{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7d777-421f-4ae2-bd19-a2df2f7048f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3fc77-d9b2-47dd-8464-faa7c82180e0",
   "metadata": {},
   "source": [
    "# Data Citation\n",
    "\n",
    "Realinho, V., Vieira Martins, M., Machado, J., & Baptista, L. (2021). Predict Students' Dropout and Academic Success [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5MC89.\n",
    "\n",
    "Link: https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0aab7b-e669-4957-a534-99110291dfcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be912541-ee03-47fb-b178-32a1ddd2d13a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1fd05-00b0-4161-8ad8-7ca604fbde66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634fd72-475d-4f88-bc8d-e849ff87d943",
   "metadata": {},
   "source": [
    "Since we are considering the success of students, I will only include students who graduated versus dropped out from college. This is due to students that have an enrolled status do not consider to be success nor non-success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f204478-b95e-4779-b99d-9c52ab83ea9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df['Target']!= 'Enrolled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c818ac-6a21-4fb0-8d97-ce25c7afe0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733077e-b9ca-4926-af29-d66da327a6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Target'] = (df['Target'] == 'Dropout').astype(int) #dropout == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8ee7b-b3a7-4770-bb30-251d074c8b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bda6c7-436d-4815-be7e-3fee00b2b6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isna().sum() #examining whether there is null data, there is none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa5068-ed3f-4fec-9ce7-b6514b3fec94",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "Now that we have converted the Target column to binary numbers, we can graph out different factors and see how they impact student success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabefa83-6c96-44c6-a93f-d2b731739a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label in df.columns[:-1]:\n",
    "    plt.hist(df[df['Target']==1][label], color = 'blue', label='Dropout', alpha=0.7, density=True)\n",
    "    plt.hist(df[df['Target']==0][label], color = 'red', label='Graduated', alpha=0.7, density = True)\n",
    "    plt.title(label)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41167827-35c8-490d-9b0a-86c91b59d904",
   "metadata": {},
   "source": [
    "# Train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbeb4c-6334-4a76-91f3-178013029d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))]) #60% train, 20% valid, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cf589-201a-4b96-9cfc-dc66c8dc8140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a57d35-4e28-42e1-9edd-d25ce2f77bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe):\n",
    "    X = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9e284-0361-47c2-852a-1008f7fa3144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, X_train, y_train = scale_dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28d1a7-3294-4d78-8468-f5cffbbcde54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid, X_valid, y_valid = scale_dataset(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f35fc8-f5a3-421e-915c-3053919f8f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test, X_test, y_test = scale_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ed1be-4720-413a-80be-fa4bd5f760f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55b663-9b2e-4b91-8e4b-7f7ee93eda93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a647528-c650-4225-bb72-e091d8a84f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061bffa-bc28-4d56-8769-fb01eb9c2b4c",
   "metadata": {},
   "source": [
    "# knn\n",
    "determining the class by its distance to data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ac106-931f-4724-b849-eda3eb403693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa8432-fd1b-4a60-85d9-23144738177c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43320f-6e2a-4bc3-9268-b8162d199e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0d767-51b1-48b3-86fe-3d74ff1e2815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318048e-626e-4aa4-ac33-b4e28ac40274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100f3c3-d2e8-40cc-a1ad-53e66ef0048e",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "The accuracy is quite good, but we can test out other models to find the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8ff39-cbc0-495c-b967-6b152967c3c1",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "(A|B)*P(B)/P(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70cb4b7-dc3f-41f7-b6b4-ee3ed22eddaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fce45-cbbd-4313-85c1-c6f75d6358ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model = nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe95890-5374-45b0-b683-dae7575e59cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a8820-9918-44b4-985f-0467232bb95b",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "This accuracy is even better. With a higher recall (which means out of all the predicted dropouts, 87 percentage are actually dropouts, which is pretty good). Let's try the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e8de1d-83ab-4eea-8608-804ebd045be5",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "relationship between coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78099c99-d00a-4ad5-b7f6-480335e001be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797deb45-7507-495a-903a-3824568b2dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model = lg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8021b1-fe39-4d8a-9948-8bab3b66f4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = lg_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29770e9c-efa0-4b16-acca-a6b8d295c319",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "This one is the best so far, with 0.96 recall and 0.89 accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db22715-fd49-41ec-98f2-7b1aa1e292aa",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "draw a line to separate the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f9b4d-143d-4c9f-8f66-d3023cd8102f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13ce35-cdf1-48b3-ae67-daeb01222239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model = svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb908de6-7607-4ffc-af23-70031c3647a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ba076-f773-49dc-92d2-2ed256806b6f",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "This one has a higher recall, but lower precision and accuracy. So I would still consider the logistic model to be the most optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb68d3-9bd2-43e7-ba22-8b855c0992a9",
   "metadata": {},
   "source": [
    "# Neutral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc3daf2-f5ec-4326-add4-fff1ae58fb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd452b2d-192e-4b17-a07a-b2510758f953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4cf191-9c96-41da-84a7-92f35c0d4301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StudentNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(StudentNN, self).__init__()\n",
    "        # Define the architecture\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # First layer (input_dim is number of features)\n",
    "        self.fc2 = nn.Linear(128, 64)         # Second layer\n",
    "        self.fc3 = nn.Linear(64, 32)          # Third layer\n",
    "        self.fc4 = nn.Linear(32, 1)           # Output layer (1 for dropout or graduation)\n",
    "        self.relu = nn.ReLU()                 # ReLU activation\n",
    "        self.sigmoid = nn.Sigmoid()           # Sigmoid for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)        # First layer\n",
    "        x = self.relu(x)       # Apply ReLU activation\n",
    "        x = self.fc2(x)        # Second layer\n",
    "        x = self.relu(x)       # Apply ReLU activation\n",
    "        x = self.fc3(x)        # Third layer\n",
    "        x = self.relu(x)       # Apply ReLU activation\n",
    "        x = self.fc4(x)        # Output layer\n",
    "        x = self.sigmoid(x)    # Sigmoid activation (output probability)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057cfa6f-3332-41ac-8b30-7871c6eb8458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_small = X_train[:1000]\n",
    "y_train_small = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6f2e2-4024-42a6-aef8-ff67d5e28753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2c1e2-445c-4578-8fd7-5563246106f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d461a07-d8f9-455a-830f-ec076fb8cb00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_small, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_small, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276acd1-3742-4878-8664-c65397ddb2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = StudentNN(input_dim=X_train.shape[1]) #X_train rows\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass (compute gradients)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:  # Print loss every 10 epochs\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00afd4-9262-4ebb-8598-1d7823cb98a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()  # Set model to evaluation mode (disables dropout, batch norm, etc.)\n",
    "with torch.no_grad():  # Disable gradient calculation for testing\n",
    "    # Forward pass on test data\n",
    "    outputs = model(X_test_tensor)\n",
    "    \n",
    "    # Convert outputs to predicted class (0 or 1)\n",
    "    predicted = (outputs > 0.5).float()  # Sigmoid output > 0.5 means predicted 1, else 0\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "    print(f'Accuracy on test data: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97dc476-3774-489e-aaa0-cdb08fca2aac",
   "metadata": {},
   "source": [
    "# Based on the models, it seems like logistic model is the best fit since it has the highest accuracy, precision, and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c12bd3-d344-4245-980e-5815e389596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "import joblib\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfdfe0-0622-4ada-bd04-8dcd5a5d4927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(lg_model, 'logistic_regression_model.pkl')\n",
    "\n",
    "# Optionally, save the scaler as well if you used it for scaling features\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6b10b-a62c-4fea-b3ee-7b6659854b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = joblib.load('logistic_regression_model.pkl')\n",
    "\n",
    "# Load the scaler (if applicable)\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Assume you have new data for prediction (let's call it X_new)\n",
    "# Don't forget to scale the new data the same way as the training data\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = model.predict(X_new_scaled)\n",
    "\n",
    "# If you want probability predictions (in case you're working with classification probabilities)\n",
    "probabilities = model.predict_proba(X_new_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
